version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
  broker:
    image: confluentinc/cp-kafka:7.0.1
    container_name: broker
    ports:
      - "9092:9092"
    expose:
      - 9092
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  centos:
    container_name: centos
    image: centos
    ports:
      - "9308:9308"
    depends_on:
      - broker
    volumes:
      - type: bind
        source: ./kafka_exporter
        target: /home/appuser/kafka_exporter
    command: sh -c "sleep 15 && /home/appuser/kafka_exporter --kafka.server=broker:9092 --kafka.version=3.3.1 --log.enable-sarama"
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    depends_on:
      - broker
    environment:
      KAFKA_CLUSTERS_0_NAME: broker
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:9092 # SSL LISTENER!
  grafana:
    image: grafana/grafana-enterprise
    container_name: grafana
    ports:
     - 3000:3000
    volumes:
      - ./Grafana-Storage/grafana.db:/var/lib/grafana/grafana.db
    command: ["cd", "/usr/share/grafana/bin/", "&&", "grafana-cli", "admin", "reset-admin-password", "${GRAFANA_ADMIN_PASSWORD}"]
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./Prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
  producer:
    container_name: producer
    build:
      context: .
      dockerfile: ./Python-Producer/Dockerfile
    restart: always
  influxdb:
    container_name: influxdb
    image: 'influxdb:1.8'
    ports:
      - '8086:8086'
    environment:
      INFLUXDB_DB: "${DATABASE_NAME}"
  consumer:
    container_name: consumer
    build:
      context: .
      dockerfile: ./Python-Consumer/Dockerfile
    restart: always
    depends_on:
      - influxdb
      - producer
  opensearch:
    image: opensearchproject/opensearch
    container_name: opensearch
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node # Nodes eligible to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - ES_JAVA_OPTS= "-Xmx2048m -Xms2048m"
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
      - 9600:9600
    volumes:
      - ./.env:/usr/share/opensearch/.env
    env_file:
      - ./.env
  opensearch-dashboard:
    image: opensearchproject/opensearch-dashboards
    container_name: opensearch-dashboard
    ports:
      - 5601:5601
    depends_on:
      - opensearch
    environment:
      OPENSEARCH_HOSTS: '["https://opensearch:9200"]'